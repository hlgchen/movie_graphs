{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c47a0d2-11d0-40e3-8d77-a84765f24ab2",
   "metadata": {},
   "source": [
    "In this notebook we implemented a simple embedding recommender. Using light GCN we diffuse the embeddings across edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc97baf-39fe-450e-add4-40f8c5a59089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4142c-593f-4d9f-ac72-57bbd91fd7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import math\n",
    "import json\n",
    "import ast\n",
    "\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "from model import SimpleEmbedding\n",
    "import evaluation\n",
    "from utils import *\n",
    "from features import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e18784-3b56-49fa-a42c-d5af9b9a2aad",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3e37d-a9b1-4207-b671-70feab7218dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../data/movies_metadata.csv\")\n",
    "ratings = pd.read_csv(\"../data/ratings.csv\")\n",
    "links = pd.read_csv(\"../data/links.csv\", dtype=str)\n",
    "credits = pd.read_csv(\"../data/credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02044660-ebfb-49fb-bc86-057647bbbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.columns = meta.columns.str.lower()\n",
    "ratings.columns = ratings.columns.str.lower()\n",
    "links.columns = links.columns.str.lower()\n",
    "\n",
    "meta = meta.rename(columns={\"id\": \"tmdbid\"})\n",
    "credits = credits.rename(columns={\"id\": \"tmdbid\"})\n",
    "\n",
    "links.tmdbid = links.tmdbid.dropna().astype(int)\n",
    "links.movieid = links.movieid.dropna().astype(int)\n",
    "\n",
    "meta.tmdbid = pd.to_numeric(meta.tmdbid, errors=\"coerce\")\n",
    "meta = meta.dropna(subset=[\"tmdbid\"])\n",
    "meta = meta.merge(links[[\"movieid\", \"tmdbid\"]], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92be11-98d9-40d1-bc32-aeb974132700",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.loc[ratings.userid < 1500].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ae058-4877-4a7c-942b-171de54a991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_movies = links.merge(ratings[[\"movieid\"]].drop_duplicates())\n",
    "\n",
    "meta = meta.merge(relevant_movies[[\"tmdbid\"]])\n",
    "credits = credits.merge(relevant_movies[[\"tmdbid\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62fdd2-d081-4c6c-b3db-d705c6e0c9e4",
   "metadata": {},
   "source": [
    "#### map userid and movie_id to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dddf5f-eb11-4d53-91be-72fd3ca17cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeid_userid, nodeid_movieid, userid_nodeid, movieid_nodeid = get_mapping(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93473387-7155-4915-9af1-2c87d8707167",
   "metadata": {},
   "source": [
    "## transform to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e518a-b760-4e16-9ed3-a31fc1a6fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddata = dd.from_pandas(ratings, npartitions=10)\n",
    "\n",
    "def create_edge(x): \n",
    "    return (userid_nodeid[int(x.userid)], movieid_nodeid[int(x.movieid)], x.rating)\n",
    "\n",
    "edges = ddata.map_partitions(lambda df: df.apply((lambda row: create_edge(row)), axis=1)).compute() \n",
    "edges = edges.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244efc2c-f4fe-4e9c-b8a4-1dca6eda8a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "G = nx.Graph(directed=False)\n",
    "G.add_weighted_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65467139-7886-4622-be30-7832e74d839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of nodes:\", G.number_of_nodes())\n",
    "print(\"number of edges:\", G.number_of_edges())\n",
    "cc = 2 * G.number_of_edges() / G.number_of_nodes()\n",
    "print(\"average node degree:\", cc)\n",
    "print(\"density of network:\", nx.density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b336328-e34b-4b21-a76d-cc5cc0051f18",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017c618-b957-404b-be34-7d733e8618b8",
   "metadata": {},
   "source": [
    "### get edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362bb78-15ed-4a92-babe-ae9a10e8efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_edge_list = graph_to_edge_list(G)\n",
    "\n",
    "# split edges\n",
    "split_dict = {\"train\": 0.75, \"valid\": 0.1, \"test\": 0.15}\n",
    "edges = transductive_edge_split(pos_edge_list, split_dict, seed=825)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff12168-ffbe-472a-b864-6b4274fc91cb",
   "metadata": {},
   "source": [
    "#### create negative samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4af09b-10eb-434b-acea-4ef0d556d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_edge_index = dict()\n",
    "neg_edge_index = dict()\n",
    "pos_label = dict()\n",
    "neg_label = dict()\n",
    "\n",
    "for key, ls in edges.items():\n",
    "    pos_edge_index[key] = edge_list_to_tensor(ls)\n",
    "\n",
    "    neg_edge_list = sample_negative_edges(G, len(ls))\n",
    "    neg_edge_index[key] = edge_list_to_tensor(neg_edge_list)\n",
    "\n",
    "    pos_label[key] = torch.ones(pos_edge_index[key].shape[1])\n",
    "    neg_label[key] = torch.zeros(neg_edge_index[key].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6518f14-db7a-49c5-bf18-44401770f930",
   "metadata": {},
   "source": [
    "### Process Movie Features using Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f27a28-9249-48b9-8e32-385a9dbca944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess metadata so we can have features\n",
    "movie_data = meta[\n",
    "    [\n",
    "        \"movieid\",\n",
    "        \"tmdbid\",\n",
    "        \"adult\",\n",
    "        \"budget\",\n",
    "        \"original_language\",\n",
    "        \"genres\",\n",
    "        \"revenue\",\n",
    "        \"status\",\n",
    "        \"video\",\n",
    "        \"vote_average\",\n",
    "        \"vote_count\",\n",
    "        \"runtime\",\n",
    "        \"overview\",\n",
    "    ]\n",
    "].copy()\n",
    "movie_data = movie_data.drop_duplicates(subset=\"movieid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0540b89-2e51-415c-9311-4afada4dfb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# preprocess features\n",
    "\n",
    "movie_data['adult'] = prep_adult(movie_data['adult'])\n",
    "movie_data['video'] = prep_video(movie_data['video'])\n",
    "movie_data['budget'] = prep_budget(movie_data['budget'])\n",
    "movie_data['original_language'] = prep_lang(movie_data['original_language'], movie_data)\n",
    "movie_data['revenue'] = prep_rev(movie_data['revenue'])\n",
    "movie_data['status'] = prep_status(movie_data['status'], movie_data)\n",
    "movie_data['vote_average'] = prep_rating(movie_data['vote_average'])\n",
    "movie_data['vote_count'] = prep_votes(movie_data['vote_count'])\n",
    "movie_data['runtime'] = prep_votes(movie_data['runtime'])\n",
    "\n",
    "one_hot_genres = prep_genres(movie_data['genres'])\n",
    "movie_data = pd.concat([movie_data, one_hot_genres], axis=1)\n",
    "\n",
    "#Come back to bag of words if we have time/if required for better performance \n",
    "movie_data = movie_data.drop(columns=['overview', 'genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22dda2a-ce38-495d-a384-80f4764748e5",
   "metadata": {},
   "source": [
    "### Process Movie Features using Social Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1198e619-0e94-4ce1-9493-db08e682e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cdf = preprocess_credits(credits)\n",
    "cdf = cdf.drop_duplicates(subset=[\"tmdbid\"])\n",
    "H = get_graph(cdf.people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3447582-a51c-464d-9007-0356319b26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_people = get_high_degree_people(H, 20)\n",
    "connected_people = [person[0] for person in connected_people]\n",
    "cdf[\"connected_people\"] = cdf.people.apply(\n",
    "    lambda x: [p for p in x if p in connected_people]\n",
    ")\n",
    "one_hot_people = pd.concat(\n",
    "    [cdf[[\"tmdbid\"]], prep_connected_people(cdf.connected_people)], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f686b6f4-982f-484c-b815-44ff2b60e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = movie_data.merge(one_hot_people, how=\"outer\")\n",
    "\n",
    "movie_data = pd.DataFrame(movieid_nodeid.keys(), columns=[\"movieid\"]).merge(\n",
    "    movie_data, how=\"left\"\n",
    ")\n",
    "\n",
    "movie_data = movie_data[(movie_data.var()[movie_data.var() > 0]).index].drop(\n",
    "    columns=[\"tmdbid\", \"movieid\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c33eaa-57e2-4825-8d7f-6f9efb2c1957",
   "metadata": {},
   "source": [
    "### Train Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0742f66b-378b-4901-a4b3-c2dbd0e7465f",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b53499-0023-4be0-b6f5-6775f1a13c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    train_label,\n",
    "    train_edge,\n",
    "    valid_label=None,\n",
    "    valid_edge=None,\n",
    "    epochs=5000,\n",
    "    early_stopping=3,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Training loop for SimpleEmbedding Model.\n",
    "\n",
    "    Params:\n",
    "        - model: SimpleEmbedding Model\n",
    "        - train_label: torch.Tensor with labels corresponding to train_edges\n",
    "                        shape: ([num_pos_edges + num_neg_edges])\n",
    "        - train_edge: torch.Tensor with training edges (should be in same order as train_label)\n",
    "                        shape: ([2, num_pos_edges + num_neg_edges])\n",
    "        - valid_label: analogous to train_label\n",
    "        - valid_edge: analogous to train_edge\n",
    "        - epochs: number of maximum epochs to train\n",
    "        - early_stopping: (int) if this value is greater than 0, training is stopped if the\n",
    "                            validation accuracy goes down \"early_stopping\" times in a row.\n",
    "    \"\"\"\n",
    "\n",
    "    learning_rate = 0.003\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    descreasing = 0\n",
    "    valid_accuracy = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(train_edge)\n",
    "        loss = loss_fn(pred, train_label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if valid_edge is not None:\n",
    "            pred_validation = model(valid_edge)\n",
    "            valid_accuracy_new = accuracy(pred_validation, valid_label)\n",
    "            if early_stopping > 0:\n",
    "                if valid_accuracy_new < valid_accuracy:\n",
    "                    decreasing += 1\n",
    "                else:\n",
    "                    decreasing = 0\n",
    "                if decreasing == early_stopping:\n",
    "                    break\n",
    "            valid_accuracy = valid_accuracy_new\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print_message = f\"epoch {i}: loss is: {loss:.3f}, accuracy train: {accuracy(pred, train_label)}\"\n",
    "            if valid_edge is not None:\n",
    "                print_message += f\" valid: {valid_accuracy}\"\n",
    "            print(print_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9170ba2-708e-4642-9fc7-24848915317b",
   "metadata": {},
   "source": [
    "### Create Initial Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd3950-bafd-4362-b03c-c7651cbccb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "emb = create_node_emb(\n",
    "    num_node=G.number_of_nodes(),\n",
    "    embedding_dim=16,\n",
    "    random_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442112d-7f0c-4d34-9c66-aa61d2d9103e",
   "metadata": {},
   "source": [
    "#### Initialize Embedding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfed80a-150b-4f32-a72c-4ef6a57352fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_embedding_model = SimpleEmbedding(emb)\n",
    "\n",
    "train_label = torch.cat([pos_label[\"train\"], neg_label[\"train\"]], dim=0)\n",
    "train_edge = torch.cat([pos_edge_index[\"train\"], neg_edge_index[\"train\"]], dim=1)\n",
    "\n",
    "valid_label = torch.cat([pos_label[\"valid\"], neg_label[\"valid\"]], dim=0)\n",
    "valid_edge = torch.cat([pos_edge_index[\"valid\"], neg_edge_index[\"valid\"]], dim=1)\n",
    "\n",
    "train(\n",
    "    simple_embedding_model,\n",
    "    train_label,\n",
    "    train_edge,\n",
    "    valid_label,\n",
    "    valid_edge,\n",
    "    early_stopping=3,\n",
    "    epochs=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e83580f-b51b-4f73-bc59-f8fb7bd609cb",
   "metadata": {},
   "source": [
    "### Recall@100 on Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8972f5-34b2-4e8f-b6ee-08b233833c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall100_simple_embedding_model = evaluation.avg_recall_at_k(\n",
    "    seen_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    test_edges=pos_edge_index[\"test\"],\n",
    "    model=simple_embedding_model,\n",
    "    library=nodeid_movieid.keys(),\n",
    "    users=nodeid_userid.keys(),\n",
    "    k=100,\n",
    ")\n",
    "\n",
    "recall100_simple_embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d6d888-5148-4152-9fba-eb8544e49984",
   "metadata": {},
   "source": [
    "## improve model by using Light GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3da919-4876-4f7c-89ff-846c93f5ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c085cb8-7aff-45a2-9405-3c4526083de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgcn_embedding_model(emb_weight, message_edges, n_layers, edge_weight=None):\n",
    "    \"\"\"\n",
    "    Returns Embedding model where embedding weights are the outcome of LGCN smoothing.\n",
    "    params:\n",
    "        - emb_weight: Embedding weight to be smoothed with LGCN\n",
    "        - message_edges: edges along which LGCN should pass embeddings for smoothing\n",
    "        - n_layers: number of LGCN layers\n",
    "        - edge_weight: if specified smoothing takes edge weight into account\n",
    "\n",
    "    \"\"\"\n",
    "    lgcn = LightGCN(n_layers)\n",
    "    res = lgcn.forward(emb_weight, message_edges, edge_weight=edge_weight)\n",
    "\n",
    "    lgcn_emb = nn.Embedding(emb.num_embeddings, emb.embedding_dim)\n",
    "    lgcn_emb.weight = nn.Parameter(res)\n",
    "\n",
    "    lgcn_emb_model = SimpleEmbedding(lgcn_emb)\n",
    "    return lgcn_emb_model\n",
    "\n",
    "\n",
    "def get_best_lgcn_layer(emb_weight, min_i=2, max_i=20, verbose=False):\n",
    "    \"\"\"\n",
    "    Returns layer number according to recall@100 on validationset.\n",
    "    Prints validation recall@100 for different layers (hyperparameter tuning of layer number)\n",
    "    params:\n",
    "        - emb: embedding to be passed along\n",
    "        - min_i: minimum layer number\n",
    "        - max_i: maximum layer number\n",
    "        - verbose: (boolean) if True outputs validation recall for each layer tried,\n",
    "                    else only the best layer\n",
    "    \"\"\"\n",
    "    best_recall = 0\n",
    "    best_param = None\n",
    "    for i in range(min_i, max_i):\n",
    "        lgcn_emb_model = get_lgcn_embedding_model(\n",
    "            emb_weight=emb_weight, message_edges=pos_edge_index[\"train\"], n_layers=i\n",
    "        )\n",
    "\n",
    "        recall_validation = evaluation.avg_recall_at_k(\n",
    "            seen_edges=pos_edge_index[\"train\"],\n",
    "            test_edges=pos_edge_index[\"valid\"],\n",
    "            model=lgcn_emb_model,\n",
    "            library=nodeid_movieid.keys(),\n",
    "            users=nodeid_userid.keys(),\n",
    "            k=100,\n",
    "        )\n",
    "        if verbose:\n",
    "            print(f\"n_layer {i} : \", recall_validation)\n",
    "        if recall_validation > best_recall:\n",
    "            best_param = i\n",
    "            best_recall = recall_validation\n",
    "    print(f\"best param: {best_param}\")\n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e115a-a22c-4d51-a7e5-3e0bcad17239",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tensor = torch.tensor(movie_data.values, dtype=torch.float32)\n",
    "feature_tensor = torch.nan_to_num(feature_tensor, nan=0)\n",
    "\n",
    "# normalize feature tensor to range [0,1]\n",
    "feature_tensor = (feature_tensor - feature_tensor.min(dim=0)[0]) / (\n",
    "    feature_tensor.max(dim=0)[0] - feature_tensor.min(dim=0)[0]\n",
    ")\n",
    "user_rand = torch.rand((len(nodeid_userid), len(movie_data.columns)))\n",
    "\n",
    "features = torch.cat([user_rand, feature_tensor], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0422dd-23cd-48c4-a2ec-62c80d155ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat([simple_embedding_model.emb.weight, features], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d3c608-68ca-44b3-9514-c372a5fef448",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = get_best_lgcn_layer(x)\n",
    "\n",
    "lgcn_simple_embedding_model = get_lgcn_embedding_model(\n",
    "    emb_weight=x,\n",
    "    message_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    n_layers=n1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec77b4-d216-43be-a21d-75449da2c7c6",
   "metadata": {},
   "source": [
    "## Testset result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c04133f-da9a-4e4d-a559-a97a827f9eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall100_lgcn_simple_embedding_model = evaluation.avg_recall_at_k(\n",
    "    seen_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    test_edges=pos_edge_index[\"test\"],\n",
    "    model=lgcn_simple_embedding_model,\n",
    "    library=nodeid_movieid.keys(),\n",
    "    users=nodeid_userid.keys(),\n",
    "    k=100,\n",
    ")\n",
    "\n",
    "recall100_lgcn_simple_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c816ed-2d60-4a45-a7d3-26a82ba42c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
