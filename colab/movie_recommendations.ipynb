{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8296946-9418-4a4c-a1a0-46233ff30571",
   "metadata": {},
   "source": [
    "In this IPython Notebook we demonstrate how to use Graph techniques to improve matrix factorization for movie recommendation. \n",
    "\n",
    "In our blogpost at [insert link] we provide more details. \n",
    "\n",
    "The underlying data set is the kaggle \"The Movies Dataset\" https://www.kaggle.com/rounakbanik/the-movies-dataset. \n",
    "\n",
    "This colab is structured as follows: \n",
    "\n",
    "0. Setup: make sure to upload an API token from kaggle into colab to load the dataset\n",
    "1. [Load Data and Networkx Graph with the data](#Load-Data)\n",
    "2. [Split Edges](#Split-Edges)\n",
    "3. [Simple Embedding (Matrix factorization) model](#Simple-Embedding-Model-(Matrix-Factorization))\n",
    "4. [Improve model by changing loss function to BRP](#Simple-Embedding-Model-with-BRP-Loss)\n",
    "5. [Improve model by smoothing the embeddings via LightGCN](#Embedding-Smoothing-with-LGCN)\n",
    "6. [Summary and Outlook](#Summary-and-Outlook)\n",
    "\n",
    "We recommend using a GPU for this Colab.\n",
    "\n",
    "Please click Runtime and then Change runtime type. Then set the hardware accelerator to <b>GPU<b/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078bcb0-8685-436e-bfbc-f0b9b3315a1e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891397b9-1183-44da-9c27-b034795bd788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requirements \n",
    "! pip install dask\n",
    "! pip install 'fsspec>=0.3.3'\n",
    "! pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cpu.html\n",
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a416143-43bb-4d53-a6c9-04f9c190d17d",
   "metadata": {},
   "source": [
    "##### Before executing the following cell: download an API token from you kaggle account (find that under Account settings) and subsequently upload the kaggle.json file into colab.\n",
    "https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26497dd3-8f76-4d52-95ef-75af5e42119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the movies data\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! mkdir data\n",
    "! mkdir data\n",
    "\n",
    "import kaggle\n",
    "kaggle.api.dataset_download_files('rounakbanik/the-movies-dataset', path='data/', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c2ffb-8de6-42c5-86f0-9fe2b477b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download supporting files (evaluation.py, utils.py) \n",
    "# from git (contains helper functions etc.)\n",
    "! curl -o evaluation.py https://raw.githubusercontent.com/hlgchen/movie_recommendations_cs224w/main/colab/evaluation.py\n",
    "! curl -o utils.py https://raw.githubusercontent.com/hlgchen/movie_recommendations_cs224w/main/colab/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624d2ae-f649-47b3-80e8-dae886176175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import evaluation\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8844f7-a914-406f-a441-7b0c87c1e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3436a7e0-e28c-41b9-8a65-d3e9e94c8f5c",
   "metadata": {},
   "source": [
    "# 1. Load Data <a name=\"Load-Data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d6f04-942a-4a95-bb05-8de99780524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "ratings.columns = ratings.columns.str.lower()\n",
    "\n",
    "# limit number of users and thus limit the dataset size \n",
    "# (otherwise graphs get too big for colab)\n",
    "ratings = ratings.loc[ratings.userid < 1500].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf959d8-4e15-4358-9200-82a3eeba9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f03e9a8-46e5-4bfe-9326-0dbc7fa09e76",
   "metadata": {},
   "source": [
    "### Map userid and movie_id to index\n",
    "\n",
    "For subsequent models, it is helpful to map users and movies to the same index space.\n",
    "We sort users by userid and movies by movieid. We map the concatenation of user and movies to nodeids. \n",
    "\n",
    "Example: if our data consists of users: [5,3] and movies [2321, 5]. We would have the following mapping: \n",
    "nodeid_userid = {1:3, 2:5},\n",
    "nodeid_movieid = {3:5, 4:2321}\n",
    "\n",
    "Note that we will only recommend movies to users that at least one user has watched in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0430b-cfd5-48c5-90d0-3d7a20709c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeid_userid, nodeid_movieid, userid_nodeid, movieid_nodeid = get_mapping(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28604cb3-4d75-423d-a7a4-79ae14074281",
   "metadata": {},
   "source": [
    "### Transform Data to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e181f-3fe5-4a2f-91f4-21679d490848",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# use dask for parallel computing (might not make a huge difference on colab)\n",
    "ddata = dd.from_pandas(ratings, npartitions=10)\n",
    "\n",
    "def create_edge(x): \n",
    "    return (userid_nodeid[int(x.userid)], movieid_nodeid[int(x.movieid)], x.rating)\n",
    "\n",
    "edges = ddata.map_partitions(lambda df: df.apply((lambda row: create_edge(row)), axis=1)).compute() \n",
    "edges = edges.tolist() # list of tuples [(node1, node2, weight)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f997779-d4c2-423d-a328-6f03de86a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "G = nx.Graph(directed=False)\n",
    "G.add_weighted_edges_from(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d6139-fd4b-4f1c-8c50-c4f2e6a1f6d6",
   "metadata": {},
   "source": [
    "### Calculate some Summary Statistics\n",
    "\n",
    "Since G is a networkx graph, we can use an array of networkx graph functions on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b15e2c-bc9b-4e5e-9e89-8d3dbc97e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of nodes:\", G.number_of_nodes())\n",
    "print(\"number of edges:\", G.number_of_edges())\n",
    "cc = 2 * G.number_of_edges() / G.number_of_nodes()\n",
    "print(\"average node degree:\", cc)\n",
    "print(\"density of network:\", nx.density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e1710-c79b-4d8f-b98d-67d1bf5d432e",
   "metadata": {},
   "source": [
    "### Visualization of Subset of Data\n",
    "\n",
    "Visualize the subgraph induced by node 2, 4 and all neighbors of node 2 (take these nodes and all edges that exist between them in G).\n",
    "Note that 2 and 4 are users and all neighbors of 2 are movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011504d0-e732-4ee8-ae5d-8ca3527016d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_plot = list(G.neighbors(2)) + [2, 4]\n",
    "S = G.subgraph(nodes_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03bd0f-fc16-491d-9b9f-7ca0f9bb0137",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [0 if node < 1499 else 1 for node in S.nodes()]\n",
    "pos = {2: (3, 1), 4: (7, 1)}\n",
    "pos.update({n: (i, 2) for i, n in enumerate(S.neighbors(2))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff9e7d-4d9f-429a-a904-eff28c504fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "nx.draw(\n",
    "    S,\n",
    "    cmap=plt.get_cmap(\"Greys\"),\n",
    "    pos=pos,\n",
    "    node_color=values,\n",
    "    with_labels=True,\n",
    "    font_color=\"orange\",\n",
    "    node_size=1000,\n",
    "    edgecolors=\"black\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title(\"bipartite subgraph of G\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded17081-c1fe-4f24-95ba-21b1bb0e3624",
   "metadata": {},
   "source": [
    "# 2. Split Edges <a name=\"Split-Edges\"></a>\n",
    "\n",
    "We split edges into training, validation and test edges. During training only training edges will be known to the model (note that we don't do any splits with nodes). During validation/test the model trained with training edges makes recommendations which are benchmarked against validation/test edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b636d-8fe8-4cfb-a2db-94a6631f661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_edge_list = graph_to_edge_list(G)\n",
    "\n",
    "# split edges\n",
    "split_dict = {\"train\": 0.75, \"valid\": 0.1, \"test\": 0.15}\n",
    "edges = transductive_edge_split(pos_edge_list, split_dict, seed=825)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481d946-1af8-48fe-9da2-d8904326afbf",
   "metadata": {},
   "source": [
    "# 3. Simple Embedding Model (Matrix Factorization) <a name=\"Simple-Embedding-Model-(Matrix-Factorization)\"></a>\n",
    "\n",
    "The baseline model for our blogpost is a simple embedding model which is equivalent to the popular Matrix Factorization model. \n",
    "\n",
    "We try to learn embeddings for users and movies such that wenn we take the dot product of a user with a movie we get a high value if an edge exists and low value otherwise.\n",
    "\n",
    "For the loss function we will use the binary cross entropy loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a5698c-4d5a-42e2-ab5b-071f8ea22519",
   "metadata": {},
   "source": [
    "### Model Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408ecea-a720-4d26-97fe-b9fa0f22e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEmbedding(nn.Module):\n",
    "    \"\"\"Simple embedding model for movie recommendations. The proximity of movies and users\n",
    "    is calculated as the scalarproduct between the embddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, emb):\n",
    "\n",
    "        super(SimpleEmbedding, self).__init__()\n",
    "\n",
    "        self.emb = emb\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, edges):\n",
    "        embedded_nodes = self.emb(edges) # replaces each scalar k in edges with the embedding at row k\n",
    "        s_product = torch.mul(embedded_nodes[0], embedded_nodes[1]).sum(axis=1)\n",
    "        out = self.sigmoid(s_product)\n",
    "        return out\n",
    "\n",
    "    def recommend(self, edges):\n",
    "        \"\"\"\n",
    "        Takes possible edges and predicts how likely it is to exist,\n",
    "        i.e. estimates how close both nodes in the edge are in terms of\n",
    "        their embedding.\n",
    "        Function needed for evaluation.\n",
    "\n",
    "        Returns sorted edges (by prediction score) and the sorted prediction score\n",
    "        \"\"\"\n",
    "        pred = self.forward(edges)\n",
    "        ranking = torch.argsort(pred, descending=True)\n",
    "        return edges[:, ranking], pred[ranking]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3ba1a-4117-427e-a013-d4bd6c88dfcb",
   "metadata": {},
   "source": [
    "### Create Negative Samples and Labels\n",
    "\n",
    "In order to train the model we will need negative edges (edges that don't exist). The model subsequently tries to asign high scores to edges that exist, and low scores to those that don't. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da337e20-1975-4cb2-8a4f-88621753ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_edge_index = dict()\n",
    "neg_edge_index = dict()\n",
    "pos_label = dict()\n",
    "neg_label = dict()\n",
    "\n",
    "for key, ls in edges.items():\n",
    "    pos_edge_index[key] = edge_list_to_tensor(ls)\n",
    "\n",
    "    neg_edge_list = sample_negative_edges(G, len(ls))\n",
    "    neg_edge_index[key] = edge_list_to_tensor(neg_edge_list)\n",
    "\n",
    "    pos_label[key] = torch.ones(pos_edge_index[key].shape[1])\n",
    "    neg_label[key] = torch.zeros(neg_edge_index[key].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0ceab-3fd7-434c-aa42-e1002050a4fd",
   "metadata": {},
   "source": [
    "### Train Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe02b1-3f52-4ca0-9b1d-930981dd8702",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0c326-ff0e-4e41-9934-83ea6e3312ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    train_label,\n",
    "    train_edge,\n",
    "    valid_label=None,\n",
    "    valid_edge=None,\n",
    "    epochs=5000,\n",
    "    early_stopping=3,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Training loop for SimpleEmbedding Model.\n",
    "\n",
    "    Params:\n",
    "        - model: SimpleEmbedding Model\n",
    "        - train_label: torch.Tensor with labels corresponding to train_edges\n",
    "                        shape: ([num_pos_edges + num_neg_edges])\n",
    "        - train_edge: torch.Tensor with training edges (should be in same order as train_label)\n",
    "                        shape: ([2, num_pos_edges + num_neg_edges])\n",
    "        - valid_label: analogous to train_label\n",
    "        - valid_edge: analogous to train_edge\n",
    "        - epochs: number of maximum epochs to train\n",
    "        - early_stopping: (int) if this value is greater than 0, training is stopped if the\n",
    "                            validation accuracy goes down \"early_stopping\" times in a row.\n",
    "    \"\"\"\n",
    "\n",
    "    learning_rate = 0.003\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    descreasing = 0\n",
    "    valid_accuracy = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(train_edge)\n",
    "        loss = loss_fn(pred, train_label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if valid_edge is not None:\n",
    "            pred_validation = model(valid_edge)\n",
    "            valid_accuracy_new = accuracy(pred_validation, valid_label)\n",
    "            if early_stopping > 0:\n",
    "                if valid_accuracy_new < valid_accuracy:\n",
    "                    decreasing += 1\n",
    "                else:\n",
    "                    decreasing = 0\n",
    "                if decreasing == early_stopping:\n",
    "                    break\n",
    "            valid_accuracy = valid_accuracy_new\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print_message = f\"epoch {i}: loss is: {loss:.3f}, accuracy train: {accuracy(pred, train_label)}\"\n",
    "            if valid_edge is not None:\n",
    "                print_message += f\" valid: {valid_accuracy}\"\n",
    "            print(print_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ca1ca-af07-4e6b-9684-3caedbe2ef4d",
   "metadata": {},
   "source": [
    "#### Initialize Embedding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d019877-71b3-42b1-9c98-8bfe62999d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "emb = create_node_emb(num_node=G.number_of_nodes()).to(device)\n",
    "simple_embedding_model = SimpleEmbedding(emb)\n",
    "\n",
    "train_label = torch.cat([pos_label[\"train\"], neg_label[\"train\"]], dim=0).to(device)\n",
    "train_edge = torch.cat([pos_edge_index[\"train\"], neg_edge_index[\"train\"]], dim=1).to(device)\n",
    "\n",
    "valid_label = torch.cat([pos_label[\"valid\"], neg_label[\"valid\"]], dim=0).to(device)\n",
    "valid_edge = torch.cat([pos_edge_index[\"valid\"], neg_edge_index[\"valid\"]], dim=1).to(device)\n",
    "\n",
    "train(simple_embedding_model, train_label, train_edge, valid_label, valid_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57905dce-008b-4d3c-86db-37eab9c6d7cb",
   "metadata": {},
   "source": [
    "### Recall@100 on Testset\n",
    "\n",
    "Recall@100 measures what percentage of movies actually watched by an user appear in the top 100 recommendations made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163ce31-938e-496d-be75-37653cb9211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall100_simple_embedding_model = evaluation.avg_recall_at_k(\n",
    "    seen_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    test_edges=pos_edge_index[\"test\"],\n",
    "    model=simple_embedding_model,\n",
    "    library=nodeid_movieid.keys(),\n",
    "    users=nodeid_userid.keys(),\n",
    "    k=100,\n",
    ")\n",
    "\n",
    "recall100_simple_embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e28ea-0013-45e8-9f78-12dc2ee58f69",
   "metadata": {},
   "source": [
    "# 4. Simple Embedding Model with BRP Loss <a name=\"Simple-Embedding-Model-with-BRP-Loss\"></a>\n",
    "\n",
    "Because we care about Recall@k, the binary cross entropy loss might not be the best choice as the loss function. Using the BRP loss we can achieve better performances.\n",
    "\n",
    "For BRP loss to work, we need a different way of sampling negative edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa8874-7416-40bb-994f-434601378566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative edges will be sampled on the fly during training\n",
    "pos_edge_index = dict()\n",
    "for key, ls in edges.items():\n",
    "    pos_edge_index[key] = edge_list_to_tensor(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc513a-4250-4e35-9c80-38dc24df6264",
   "metadata": {},
   "source": [
    "### Train Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14bf47-b915-464c-a799-9d6ac02d9830",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676851bb-e5a9-4830-85a8-b7f682d8d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(\n",
    "    model, train_edges, n_batches, valid_edges=None, epochs=181, early_stopping=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains embeddings with BRP loss and using user batches. Negtaive Edges for each user\n",
    "    are sampled on the fly.\n",
    "\n",
    "    Params:\n",
    "        - model: SimpleEmbedding Model\n",
    "        - train_edges: torch.Tensor with shape (2, n_positive_edges).\n",
    "                    Conatains positive edges of training set.\n",
    "        - n_batches: number of user batches.\n",
    "        - valid_edges: analogous to train_edge\n",
    "        - epochs: number of maximum epochs to train\n",
    "        - early_stopping: (int) if this value is greater than 0, training is stopped if the\n",
    "                            validation accuracy goes down \"early_stopping\" times in a row.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    learning_rate = 0.003\n",
    "    optimizer = Adam(emb.parameters(), lr=learning_rate)\n",
    "\n",
    "    users, unique_users, index = get_pos_edges_users(train_edges)\n",
    "    _, unique_movies, _ = get_pos_edges_movies(train_edges)\n",
    "\n",
    "    descreasing = 0\n",
    "    valid_recall_k = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        user_batches = user_batch_generator(unique_users, n_batches)\n",
    "        for batch in user_batches:\n",
    "            optimizer.zero_grad()\n",
    "            user_losses = []\n",
    "            for u in batch:\n",
    "\n",
    "                # get positive and sample 10 negative edges for each user \n",
    "                # negative edges: (user, movies), where haven't been watched by the user \n",
    "                pos_edges_user, neg_edges_user = get_pos_neg_edges_for_user(\n",
    "                    edges=train_edges,\n",
    "                    users=users,\n",
    "                    u=u,\n",
    "                    unique_movies_set=set(unique_movies),\n",
    "                )\n",
    "\n",
    "                # make predictions and calculate loss\n",
    "                f_pos = model.forward(pos_edges_user)\n",
    "                f_neg = model.forward(neg_edges_user)\n",
    "\n",
    "                # individual brp loss for one user\n",
    "                ul = brp_loss(f_pos, f_neg)\n",
    "                user_losses.append(ul)\n",
    "\n",
    "            batch_loss = torch.stack(user_losses).mean()\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "\n",
    "            if valid_edges is not None:\n",
    "                valid_recall_k_new = evaluation.avg_recall_at_k(\n",
    "                    seen_edges=pos_edge_index[\"train\"],\n",
    "                    test_edges=pos_edge_index[\"valid\"],\n",
    "                    model=model,\n",
    "                    library=nodeid_movieid.keys(),\n",
    "                    users=nodeid_userid.keys(),\n",
    "                    k=100,\n",
    "                )\n",
    "                if early_stopping > 0:\n",
    "                    if valid_recall_k_new <= valid_recall_k:\n",
    "                        decreasing += 1\n",
    "                    else:\n",
    "                        decreasing = 0\n",
    "                    if decreasing == early_stopping:\n",
    "                        break\n",
    "                valid_recall_k = valid_recall_k_new\n",
    "\n",
    "            print(\n",
    "                f\"epoch {i}: loss is: {batch_loss}, valid recall@100: {valid_recall_k}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63caf485-313f-4b81-8659-58b96bfca69c",
   "metadata": {},
   "source": [
    "#### Initialize Embedding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291fe765-5648-4495-a3b7-905eb3ff4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "emb = create_node_emb(num_node=G.number_of_nodes()).to(device)\n",
    "\n",
    "embedding_brp_model = SimpleEmbedding(emb)\n",
    "\n",
    "# takes around 7min on colab with GPU \n",
    "batch_train(\n",
    "    embedding_brp_model,\n",
    "    pos_edge_index[\"train\"],\n",
    "    n_batches=100,\n",
    "    valid_edges=pos_edge_index[\"valid\"],\n",
    "    early_stopping=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648dd560-1811-4482-9119-c2a3d9b4978d",
   "metadata": {},
   "source": [
    "### Recall@100 on Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051226f1-4bb0-413d-a741-91741379c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall100_embedding_brp_model = evaluation.avg_recall_at_k(\n",
    "    seen_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    test_edges=pos_edge_index[\"test\"],\n",
    "    model=embedding_brp_model,\n",
    "    library=nodeid_movieid.keys(),\n",
    "    users=nodeid_userid.keys(),\n",
    "    k=100,\n",
    ")\n",
    "\n",
    "recall100_embedding_brp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c778f-c306-44c3-847d-dc45842fa48d",
   "metadata": {},
   "source": [
    "# 5. Embedding Smoothing with LGCN <a name=\"Embedding-Smoothing-with-LGCN\"></a>\n",
    "Nodes that are close to each other tend to have similar properties. Using PyG we can implement LGCN and improve our recommendations. Mathematically we are calculating $H^{(k)}$: \n",
    "\n",
    "$$H^{(K)} = \\frac{1}{K}\\sum_{k=0}^K H^{(k)}$$\n",
    " \n",
    "Where $H$ is the embedding matrix where the embedding of nodes are rows. The final embedding aquired from a LGCN with $K$ layers is the average over embeddings after $k$ step diffusion, $k \\in \\{1,.., K\\}$. \n",
    "\n",
    "In particular for a single node $u$ the embedding at step $k+ 1$ is calculated as follows: $$h^{(k+1)}_u =\\sum_{m \\in N(u)} \\frac{w_{u,m}}{\\sqrt{d_u}\\sqrt{d_m}} h_m^{(k)}$$\n",
    "\n",
    "Where $w_{u,m}$ is the weight of the edge bewteen $u, m$ and $d_u$ is the node degree of node $u$. \n",
    "\n",
    "Note that $\\frac{w_{u,m}}{\\sqrt{d_u}\\sqrt{d_m}} h_m^{(k)}$ is the message, Sum is the aggregation, if we interpret it as a GNN. In contrast to typical GNNs, LGCN dosn't use non-linearities. In addition we decided not to use any learnable weights, thus the model is very simple and easy to implement (no training needed).\n",
    "\n",
    "\n",
    "\n",
    "We can interpret this process as Embeddings being smoothed within neighborhoods. (See blogpost for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b0edd3-a828-4bc5-90e4-4a5b1ce2c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcn_norm(edge_index, edge_weight=None, num_nodes=None):\n",
    "    \"\"\"\n",
    "    Returns edge index and edge weight that corresonds to edge diffusion matrix\n",
    "    D^-0.5 A D^-0.5. A is the (weighted) adjacency matrix. \n",
    "\n",
    "    Params:\n",
    "        - edge_index: tensor of shape (2, n_edges) containing edges\n",
    "        - edge_weight: tensor of shape (n_edges, ) containing weights of each edge\n",
    "        - num_nodes: integer with number of nodes of the graph\n",
    "\n",
    "    Returns:\n",
    "        - edge_index: edge index that was passed to the function\n",
    "        - weight: tensor of shape (n_edges, ) containing weights that correspond to diffusion\n",
    "\n",
    "    \"\"\"\n",
    "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "\n",
    "    if edge_weight is None:\n",
    "        edge_weight = torch.ones(\n",
    "            (edge_index.size(1),), dtype=torch.float, device=edge_index.device\n",
    "        )\n",
    "\n",
    "    row, col = edge_index[0], edge_index[1]\n",
    "    deg = scatter_add(edge_weight, col, dim=0, dim_size=num_nodes)\n",
    "    deg_inv_sqrt = deg.pow_(-0.5)\n",
    "    deg_inv_sqrt.masked_fill_(deg_inv_sqrt == float(\"inf\"), 0)\n",
    "    return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30b7ad8-825c-49cf-8112-93164f78728c",
   "metadata": {},
   "source": [
    "### Model Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf04cc0-f405-43c7-a81f-6828df9edeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super(LightGCNConv, self).__init__()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # propagate starts the message passing process\n",
    "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        # constructs message that is to be passed from neigbor node j to central node i\n",
    "        # here message is value of x_j (embedding of x_j at given step)\n",
    "        # multiplied with edge_weight (that was calculated by gcn_norm in this tutorial)\n",
    "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
    "\n",
    "\n",
    "class LightGCN(torch.nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "\n",
    "        super(LightGCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList([LightGCNConv() for i in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, adj_t, adj_t_is_undirected=True, edge_weight=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Diffuses x in neighborhood num_layers of times using diffusion matrix D^-0.5 A D^-0.5\n",
    "        Params: \n",
    "            - x: torch.tensor with shape (n_nodes, ..), for our purposes\n",
    "                    this will be the embedding matrix \n",
    "            - adj_t: torch tensor with edges for message propagation\n",
    "                    has shape (2, num_edges_for_message_propagation)\n",
    "                    Can be seen as different form of adjacency matrix. \n",
    "                    adj_t is renamed to edge_index to follow the PyG conventions.\n",
    "            - adj_t_is_undirected: if true it means adj_t is a list that contains unordered edges \n",
    "                    (edges are not directed)\n",
    "            - edge_weight: torch tensor with weights for each edge. \n",
    "                    Should have shape [adj_t.shape[1]].\n",
    "        \"\"\"\n",
    "\n",
    "        # For message passing, Edges have to be directed\n",
    "        # networkx graph edges are undirected by default\n",
    "        # implementation assumes that there are no self loops\n",
    "        # otherwise these would be duplicated\n",
    "        if adj_t_is_undirected:\n",
    "            adj_t_reversed = adj_t[[1, 0], :] # create reversed versions of edges\n",
    "            adj_t = torch.cat([adj_t, adj_t_reversed], dim=1)\n",
    "\n",
    "            if edge_weight is not None:\n",
    "                edge_weight = torch.cat([edge_weight, edge_weight])\n",
    "\n",
    "        out_ls = [x]\n",
    "        edge_index, edge_weight = gcn_norm(\n",
    "            adj_t, edge_weight=edge_weight, num_nodes=x.size(0)\n",
    "        )\n",
    "\n",
    "        for i in range(len(self.convs)):\n",
    "            x = self.convs[i](x, edge_index, edge_weight)\n",
    "            out_ls.append(x)\n",
    "        return torch.stack(out_ls).mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86e5f7-445a-4ac9-8558-74b9b7a4be3b",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa187ca8-7867-474e-a715-3f8732959f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgcn_embedding_model(emb, message_edges, n_layers, edge_weight=None):\n",
    "    \"\"\"\n",
    "    Returns Embedding model where embedding weights are the outcome of LGCN smoothing.\n",
    "    params:\n",
    "        - emb: Embedding to be smoothed with LGCN\n",
    "        - message_edges: edges along which LGCN should pass embeddings for smoothing\n",
    "        - n_layers: number of LGCN layers\n",
    "        - edge_weight: if specified smoothing takes edge weight into account\n",
    "\n",
    "    \"\"\"\n",
    "    lgcn = LightGCN(n_layers)\n",
    "    res = lgcn.forward(emb.weight, message_edges, edge_weight=edge_weight)\n",
    "\n",
    "    lgcn_emb = nn.Embedding(emb.num_embeddings, emb.embedding_dim).to(device)\n",
    "    lgcn_emb.weight = nn.Parameter(res)\n",
    "\n",
    "    lgcn_emb_model = SimpleEmbedding(lgcn_emb)\n",
    "    return lgcn_emb_model\n",
    "\n",
    "\n",
    "def get_best_lgcn_layer(emb, min_i=2, max_i=20, verbose=False):\n",
    "    \"\"\"\n",
    "    Returns layer number according to recall@100 on validationset.\n",
    "    Prints validation recall@100 for different layers (hyperparameter tuning of layer number)\n",
    "    params:\n",
    "        - emb: embedding to be passed along\n",
    "        - min_i: minimum layer number\n",
    "        - max_i: maximum layer number\n",
    "        - verbose: (boolean) if True outputs validation recall for each layer tried,\n",
    "                    else only the best layer\n",
    "    \"\"\"\n",
    "    best_recall = 0\n",
    "    best_param = None\n",
    "    for i in range(min_i, max_i):\n",
    "        lgcn_emb_model = get_lgcn_embedding_model(\n",
    "            emb=emb, message_edges=pos_edge_index[\"train\"], n_layers=i\n",
    "        )\n",
    "\n",
    "        recall_validation = evaluation.avg_recall_at_k(\n",
    "            seen_edges=pos_edge_index[\"train\"],\n",
    "            test_edges=pos_edge_index[\"valid\"],\n",
    "            model=lgcn_emb_model,\n",
    "            library=nodeid_movieid.keys(),\n",
    "            users=nodeid_userid.keys(),\n",
    "            k=100,\n",
    "        )\n",
    "        if verbose:\n",
    "            print(f\"n_layer {i} : \", recall_validation)\n",
    "        if recall_validation > best_recall:\n",
    "            best_param = i\n",
    "            best_recall = recall_validation\n",
    "    print(f\"best param: {best_param}\")\n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7d099-c352-4b78-b1b3-7a136a0f311b",
   "metadata": {},
   "source": [
    "#### Tune Number of LGCN Layers with Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a190c0d-e872-4f5a-9099-c030bf5e08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = get_best_lgcn_layer(simple_embedding_model.emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ddfd24-6668-4df1-95f2-3fce5259b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2 = get_best_lgcn_layer(embedding_brp_model.emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d6301-2873-4528-8a46-b232d69f7e1d",
   "metadata": {},
   "source": [
    "### improve base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1469848-0dae-4585-b938-9a9554501499",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgcn_simple_embedding_model = get_lgcn_embedding_model(\n",
    "    emb=simple_embedding_model.emb,\n",
    "    message_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    n_layers=n1,\n",
    ")\n",
    "\n",
    "lgcn_embedding_brp_model = get_lgcn_embedding_model(\n",
    "    emb=embedding_brp_model.emb,\n",
    "    message_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    n_layers=n2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8209f6-50a4-49fd-aa3e-6c1ea88e1e9f",
   "metadata": {},
   "source": [
    "### Recall@100 on Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0a3b2-2b4f-44c4-9648-c5c1024e8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall100_lgcn_simple_embedding_model = evaluation.avg_recall_at_k(\n",
    "    seen_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    test_edges=pos_edge_index[\"test\"],\n",
    "    model=lgcn_simple_embedding_model,\n",
    "    library=nodeid_movieid.keys(),\n",
    "    users=nodeid_userid.keys(),\n",
    "    k=100,\n",
    ")\n",
    "\n",
    "recall100_lgcn_simple_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e12fda-6208-48a9-8122-e3ac51bd1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall100_lgcn_embedding_brp_model = evaluation.avg_recall_at_k(\n",
    "    seen_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    test_edges=pos_edge_index[\"test\"],\n",
    "    model=lgcn_embedding_brp_model,\n",
    "    library=nodeid_movieid.keys(),\n",
    "    users=nodeid_userid.keys(),\n",
    "    k=100,\n",
    ")\n",
    "\n",
    "recall100_lgcn_embedding_brp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a19eb0e-aaf0-4820-8ccd-0d8540ca0361",
   "metadata": {},
   "source": [
    "### Bonus: Possible Improvement of Embedding by Using Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b59a79-541d-4c72-a5ef-5e04369580f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(edges):\n",
    "    \"\"\"Returns tensor of shape [(number of edges)] with edge weights for each edge.\"\"\"\n",
    "    ls = []\n",
    "    for i in range(edges.shape[1]):\n",
    "        edge = edges[:, i]\n",
    "        r = G.get_edge_data(*edge.tolist())[\"weight\"]\n",
    "        ls.append(r)\n",
    "    return torch.tensor(ls, device=device)\n",
    "\n",
    "\n",
    "edge_w_ratings = get_ratings(\n",
    "    torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bf19f5-1214-43b8-ae13-cd73d44135bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgcn_embedding_brp_model_ratings = get_lgcn_embedding_model(\n",
    "    emb=embedding_brp_model.emb,\n",
    "    message_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    n_layers=n2,\n",
    "    edge_weight=edge_w_ratings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217caf7-847c-4a58-b7d4-3ee04871cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall100_lgcn_embedding_brp_model_ratings = evaluation.avg_recall_at_k(\n",
    "    seen_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    test_edges=pos_edge_index[\"test\"],\n",
    "    model=lgcn_embedding_brp_model_ratings,\n",
    "    library=nodeid_movieid.keys(),\n",
    "    users=nodeid_userid.keys(),\n",
    "    k=100,\n",
    ")\n",
    "\n",
    "recall100_lgcn_embedding_brp_model_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba7b1e-d1e1-466f-8044-3bbe99812e78",
   "metadata": {},
   "source": [
    "# 6. Summary and Outlook <a name=\"Summary-and-Outlook\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08164e4-8a83-485b-96c9-70270b7eafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall@100 values for different models on test-set:\")\n",
    "print(f\"Simple Embedding: {recall100_simple_embedding_model:.6f}\")\n",
    "print(f\"Simple Embedding with BRP: {recall100_embedding_brp_model:.6f}\")\n",
    "print(f\"LGCN Simple Embedding: {recall100_lgcn_simple_embedding_model:.6f}\")\n",
    "print(f\"LGCN Simple Embedding with BRP: {recall100_lgcn_embedding_brp_model:.6f}\")\n",
    "print(\n",
    "    f\"LGCN Simple Embedding with BRP and Ratings as Weights: {recall100_lgcn_embedding_brp_model_ratings:.6f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca48b26-7f90-49e0-95f2-76ef47753cd7",
   "metadata": {},
   "source": [
    "### Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d0c51-314a-4de5-b6d1-2e43751bcd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"data/movies_metadata.csv\")\n",
    "meta.id = pd.to_numeric(meta.id, errors=\"coerce\")\n",
    "links = pd.read_csv(\"data/links.csv\")\n",
    "\n",
    "meta = meta.merge(links, left_on=\"id\", right_on=\"tmdbId\")[[\"movieId\", \"original_title\"]]\n",
    "meta.index = meta.movieId\n",
    "movie_names = meta.drop_duplicates().original_title.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe9815-97e3-412d-9d91-4a377812ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(user, model, seen_edges, test_edges, library, k):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns recommended movies, actually watched movies, \n",
    "    the intersection of the former two and movies watched during training. \n",
    "    Movies are expressed in words and not as ids. \n",
    "    \n",
    "    Params: \n",
    "        - user: (int) nodeid of user\n",
    "        - model: model to make recommendations\n",
    "        - seen_edges: edges that contains user movie interactions of the past \n",
    "                    (for testing, this should be train and validation edges)\n",
    "        - test_edges: movie user interactions that are unknown to the model\n",
    "                    these are movies that the user actually watched which will \n",
    "                    be used for benchmarking the predictions. \n",
    "        - library: library: arraylike object with all movie ids\n",
    "        - k: number of recommendations to be made\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    unwatched = evaluation.get_unwatched_movies(user, seen_edges, library)\n",
    "    unwatched = unwatched.unsqueeze(0)  # shape (1, n_unwatched_movies)\n",
    "    ranked_edges, _ = evaluation.recommend_for(user, unwatched, model)\n",
    "\n",
    "    # note that by construction movies are at index position 1\n",
    "    recommendations = ranked_edges[1, :k].tolist()\n",
    "    watched_test = evaluation.get_watched_movies(user, test_edges)\n",
    "\n",
    "    recommendations = [nodeid_movieid[n_id] for n_id in recommendations]\n",
    "    watched_test = [nodeid_movieid[n_id] for n_id in watched_test]\n",
    "\n",
    "    recommendations = [movie_names.get(m_id) for m_id in recommendations]\n",
    "    watched_test = [movie_names.get(m_id) for m_id in watched_test]\n",
    "\n",
    "    hits = set(recommendations).intersection(set(watched_test))\n",
    "    watched_train = evaluation.get_watched_movies(user, seen_edges)\n",
    "    watched_train = [movie_names[nodeid_movieid[n_id]] for n_id in watched_train]\n",
    "\n",
    "    return recommendations, watched_test, hits, watched_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08db14a-1ad0-4cbc-912e-c2093fefefe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10, actual, hits, watched = recommend_movies(\n",
    "    user=765,\n",
    "    seen_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    test_edges=pos_edge_index[\"test\"],\n",
    "    model=lgcn_embedding_brp_model_ratings,\n",
    "    library=nodeid_movieid.keys(),\n",
    "    k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f7241-899e-4bab-8589-f2d673ef87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d442ae5-8eb2-4596-8bc6-cf06aa1bcb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa9891-7447-4576-b6c4-092588e673e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9003b3-f84c-4275-b081-92f42c8445f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10, actual, hits, watched = recommend_movies(\n",
    "    user=765,\n",
    "    seen_edges=torch.cat([pos_edge_index[\"train\"], pos_edge_index[\"valid\"]], dim=1),\n",
    "    test_edges=pos_edge_index[\"test\"],\n",
    "    model=lgcn_simple_embedding_model,\n",
    "    library=nodeid_movieid.keys(),\n",
    "    k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75549749-d910-4300-a01e-2b14100bd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77d884-dabf-43fb-8efe-0591e848a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb98b24-50d2-4cc7-90cf-b3c10f166545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b96f3-21d6-4735-8e61-cffd5822b56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
